# DaShan 桌宠机器人系统开发计划

## 一、系统架构设计

### 分层架构
```
┌─────────────────────────────────────┐
│      表演层（机器人端）               │
│  - 眼睛LED显示 (WS2812B)             │
│  - 头部舵机 (2个自由度)              │
│  - 摄像头人脸追踪                    │
│  - 红外距离感知                      │
│  - ESP32-S3微控制器                  │
└─────────────────────────────────────┘
              ↓ UART/USB
┌─────────────────────────────────────┐
│      大脑层（主机端）                 │
│  - openWakeWord 唤醒检测            │
│  - Whisper 语音识别                 │
│  - GLM-4.7 对话生成                 │
│  - Piper 语音合成                   │
│  - 表情动画生成器                    │
│  - 长期记忆管理                      │
└─────────────────────────────────────┘
```

## 二、硬件清单

### 机器人端（表演层）
- ESP32-S3-WROOM-1 (双核240MHz，WiFi/BLE)
- WS2812B LED矩阵 8x8 (眼睛显示)
- SG90舵机 x2 (水平/垂直转头)
- OV2640摄像头模块
- HC-SR04超声波传感器 (红外替代)
- I2S麦克风 (INMP441)
- I2S音频功放 + 扬声器
- 3.7V锂电池 + TP4056充电模块
- 3D打印外壳 (瓦力风格)

### 主机端（大脑层）
- Raspberry Pi 5 或 高性能PC
- USB转UART模块 (与ESP32通信)

## 三、软件架构

### 机器人端 (ESP32-S3)
1. **底层驱动**
   - WS2812B LED控制
   - 舵机PWM控制
   - 摄像头图像采集
   - I2S音频输入输出
   - 串口通信协议

2. **状态机**
   - SLEEP (休眠)：眼睛半闭，呼吸灯
   - LISTEN (倾听)：注视前方，头部微倾
   - THINK (思考)：歪头，瞳孔移动
   - TALK (说话)：眼睛动画配合语音
   - IDLE (空闲)：随机微动，眨眼

3. **表情系统**
   - 15种预设表情
   - 动画过渡插值
   - 眨眼随机触发
   - 瞳孔追踪功能

### 主机端 (Python)
1. **语音处理模块**
   - openWakeWord：唤醒词检测
   - Whisper：语音转文字
   - Piper：文字转语音

2. **对话引擎**
   - GLM-4.7 API调用
   - 对话历史管理
   - 情绪状态跟踪
   - 个性化记忆库

3. **视觉模块**
   - 人脸检测 (OpenCV/face_recognition)
   - 注视点计算
   - 表情识别 (可选)
   - 距离估算

4. **行为编排**
   - 动画序列生成器
   - 节奏同步算法
   - 随机行为生成
   - 情绪到表情映射

5. **通信层**
   - UART协议封装
   - 命令队列
   - 心跳检测

## 四、交互流程设计

### 完整交互链路
```
1. SLEEP → 唤醒词检测
2. 亮眼睛 → 抬头 → 看向用户
3. LISTEN → 录音 → Whisper STT
4. 歪头思考 → 调用GLM-4.7
5. TALK → Piper TTS → 播放 + 表情动画
6. 30s无交互 → 回到SLEEP
```

## 五、开发步骤

### Phase 1: 硬件搭建 (Week 1)
- 采购硬件清单
- 3D打印外壳
- 硬件连接测试

### Phase 2: 机器人端开发 (Week 2-3)
- ESP32基础驱动
- 眼睛表情系统
- 舵机控制
- 状态机实现

### Phase 3: 主机端语音模块 (Week 4)
- openWakeWord集成
- Whisper集成
- Piper集成
- 语音流程测试

### Phase 4: GLM-4.7集成 (Week 5)
- API对接
- 对话管理
- 记忆系统
- 提示词工程

### Phase 5: 视觉追踪 (Week 6)
- 摄像头集成
- 人脸检测
- 注视算法
- 舵机联动

### Phase 6: 行为编排 (Week 7)
- 动画系统
- 节奏同步
- 情绪表达
- 随机行为

### Phase 7: 整合优化 (Week 8)
- 端到端测试
- 性能优化
- 用户体验调优
- 文档编写

## 六、核心特性

✅ **低延迟唤醒** <200ms响应
✅ **自然注视** 实时人脸追踪
✅ **情感表达** 15+表情动画
✅ **离线运行** 语音模块本地化
✅ **可扩展** 模块化设计
✅ **可升级** GLM-4.7可替换为其他LLM
✅ **低成本** 总成本 <500元

## 七、创新点

1. **表情节奏同步**：根据TTS波形生成眨眼和微动
2. **情绪传播**：从对话语气推断情绪，影响表情
3. **个性化记忆**：记住用户偏好，越用越智能
4. **随机微动**：避免死板，增加"生命力"
5. **注视预测**：预测用户视线，提前转向